<center><h1>数据挖掘 最终项目</h1></center>

<center><h3>天猫复购预测挑战</h3></center>

<center><h5>黄植滇 钱厚德 项盛业</h5h5></center>



本实验主要在python环境下完成，对数据的处理和特征的提取主要使用了sklearn和pandas的相关函数，调用模型及数据挖掘算法则调用对应的库来实现，绘图主要使用了matplotlib和seaborn进行可视化。



### 一、数据预处理

我们仅采用了`data_format1`中的数据进行预处理和后续的特征提取。我们将数据读入内存后，将部分特征转化为易于提取特征的形式（如拆分购买时间的月日数据），随后对特征进行提取。大致分为3种类型：用户、商家以及用户和商家共同考虑的分类方式。我们也做了log数据的持久化存储，这样可以在多次重复运行时提升一些性能。

### 二、数据可视化与分析

我们可以对预处理过后的数据进行一些简单的统计分析：

#### 1. 用户数据



#### 2. 商家数据



#### 3. 用户-商家数据



### 三、算法实现与分析

#### 1. 特征工程

对于预处理结果，我们需要提取出更具有差异性的特征，才能使分类效果较好。

#### 2. 挖掘算法

##### 1) Logistic模型

Logistic模型即线性回归，是一种简单的分类器，主要采用sigmoid函数和最大似然估计来得到分类概率，并使用梯度下降来拟合真实数据。这种模型的运行速度很快，但效果一般。

##### 2). MLP

MLP即多层感知机，是层与层间采用全连接方式的简单神经网络，可调整的参数包括激活函数、求解器、学习率和隐含层大小等，这种方法的训练速度较慢。

##### 3). 决策树

即为我们正常了解到的决策树，通过信息熵来计算信息增益，可调整的参数包括树的最大深度，以防止深度过大时产生过拟合。

##### 4). 随机森林

随机森林算法基于决策树，我们可以同时建立多个决策树对随机抽取数据进行分类，最后以这些树的均值作为结果返回，本质上为使用决策树进行求解的bagging算法。

##### 5). 梯度提升树

与随机森林算法类似，梯度提升树同样基于决策树，但采用了adaboost算法来综合结果，对于不同的误差损失函数和迭代方法，提升树也可以细分出多种算法，梯度提升树采用均方误差和负梯度拟合残差的方法来进行计算，在此分类问题中效果不错。

##### 6). XGBoost

xgboost是优化的提升树，是现在最常用的几种分类算法之一，优点在于训练速度较快，准确率也略高于普通的梯度提升树。

##### 7). LGBM

LightGBM同样是优化的梯度提升树算法，对于大规模的数据效果较好，对于这次分类问题，LGBM取得了最优的结果。

### 四、结果分析

##### 特征选择

删掉一些特征看结果

##### 模型选择

直接放个图

### 五、最终效果与排行榜

我们最终采用了上述的全部特征，并使用LGBM作为训练模型，在验证集上的roc_auc_score超过0.7，在测试集上的score为0.679754（ouoqwq），接近0.68:

![ranking](image/ranking.png)

### 六、队伍分工



